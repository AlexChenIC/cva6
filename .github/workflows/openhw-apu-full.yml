# Copyright 2026 OpenHW Group
# Licensed under the Apache License, Version 2.0, see LICENSE for details.
# SPDX-License-Identifier: Apache-2.0

# OpenHW Full APU Test Suite
# Comprehensive Verilator regression tests for CVA6 APU configurations
#
# Test coverage (all Verilator-compatible test suites):
#
#   RV64 configs:
#     - cv64a6_imafdc_sv39             (base)
#     - cv64a6_imafdc_sv39_hpdcache    (HPDcache)
#     - cv64a6_imafdc_sv39_hpdcache_wb (HPDcache + Write-back)
#     - cv64a6_imafdc_sv39_wb          (Write-back)
#
#   RV64 test suites per config:
#     - smoke-tests          : Quick sanity check (~6 tests) [sv39 only]
#     - dv-riscv-arch-test   : RISC-V architecture compliance (~221 tests)
#     - dv-riscv-tests       : Standard RISC-V tests, p+v mode (~229 tests)
#     - dv-riscv-compliance  : RISC-V compliance suite (~183 tests) [sv39 only]
#     - cv64a6_imafdc_tests  : CVA6-specific directed tests (~6 tests)
#     - benchmark            : Performance benchmarks (~12 programs)
#
#   RV32 (cv32a65x):
#     - smoke-tests          : Quick sanity check (~1 test)
#     - dv-riscv-arch-test   : RISC-V architecture compliance (~105 tests)
#     - dv-riscv-tests       : Standard RISC-V tests, p-mode only (~94 tests)
#     - dv-riscv-compliance  : RISC-V compliance suite (~183 tests)
#     - cv32a6_tests         : CVA6-specific directed tests (~6 tests)
#     - dv-riscv-csr-access-test : CSR access verification tests (~9 tests)
#     - benchmark            : Performance benchmarks (~12 programs)
#
#   Total: ~2471+ individual test executions across 25 parallel jobs
#     - RV64: 18 jobs (6 base + 12 variant configs)
#     - RV32: 7 jobs
#
# Not included (require VCS-UVM, not Verilator-compatible):
#   - dv-generated-tests, dv-generated-xif-tests, dv-interrupt-test
#   - smoke-gen_tests, debug_test, pmp_cv32a65x_tests
#   - dhrystone, coremark (hwconfig mode)
#   - cvxif_verif_regression
#
# Note: smoke-tests and dv-riscv-compliance run only on sv39 base config
# because their scripts hardcode target/testlist paths. The hpdcache/wb
# variants share the same sv39 testlists for arch-test, riscv-tests,
# cv64a6_imafdc_tests, and benchmark.

name: openhw-apu-full

on:
  # Manual trigger - primary usage
  workflow_dispatch:
    inputs:
      target_arch:
        description: 'Target architecture to test'
        required: true
        default: 'both'
        type: choice
        options:
          - both
          - rv32
          - rv64
  # TEMP: Enable push trigger for testing (remove after validation)
  push:
    branches:
      - 'task/**'
      - 'feature/**'
      - 'openhw/**'
  # Scheduled weekly regression (optional - uncomment to enable)
  # schedule:
  #   - cron: '0 2 * * 0'  # Every Sunday at 2:00 AM UTC

# Cancel in-progress runs for the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  SPIKE_TANDEM: 1
  NUM_JOBS: 8

jobs:
  # ============================================================
  # Stage 1: Setup and cache tools
  # ============================================================
  setup-tools:
    name: Setup Tools
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: Setup CVA6 Environment
        uses: ./.github/actions/setup-cva6-env
        with:
          install-tools: 'true'

  # ============================================================
  # Stage 2: RV64 Test Execution (parallel matrix jobs)
  # ============================================================
  execute-rv64-tests:
    name: RV64 ${{ matrix.testcase }} (${{ matrix.config }})
    runs-on: ubuntu-latest
    needs: setup-tools
    if: (github.event.inputs.target_arch || 'both') == 'both' || (github.event.inputs.target_arch || 'both') == 'rv64'
    strategy:
      fail-fast: false
      matrix:
        include:
          # ============================================================
          # cv64a6_imafdc_sv39 (base config)
          # ============================================================
          # Smoke tests - quick sanity check (~6 tests)
          - testcase: smoke-tests-cv64a6_imafdc_sv39
            config: cv64a6_imafdc_sv39
          # Architecture compliance tests (~221 tests)
          - testcase: dv-riscv-arch-test
            config: cv64a6_imafdc_sv39
          # Standard RISC-V tests - p-mode + v-mode (~229 tests)
          - testcase: dv-riscv-tests
            config: cv64a6_imafdc_sv39
          # RISC-V compliance suite (~183 tests)
          - testcase: dv-riscv-compliance
            config: cv64a6_imafdc_sv39
          # CVA6-specific directed tests (~6 tests)
          - testcase: cv64a6_imafdc_tests
            config: cv64a6_imafdc_sv39
          # Performance benchmarks (~12 programs)
          - testcase: benchmark
            config: cv64a6_imafdc_sv39

          # ============================================================
          # cv64a6_imafdc_sv39_hpdcache (HPDcache variant)
          # Note: smoke-tests/compliance skipped (hardcoded target/testlist)
          # ============================================================
          - testcase: dv-riscv-arch-test
            config: cv64a6_imafdc_sv39_hpdcache
          - testcase: dv-riscv-tests
            config: cv64a6_imafdc_sv39_hpdcache
            testlists: "../tests/testlist_riscv-tests-cv64a6_imafdc_sv39-p.yaml ../tests/testlist_riscv-tests-cv64a6_imafdc_sv39-v.yaml"
          - testcase: cv64a6_imafdc_tests
            config: cv64a6_imafdc_sv39_hpdcache
          - testcase: benchmark
            config: cv64a6_imafdc_sv39_hpdcache

          # ============================================================
          # cv64a6_imafdc_sv39_hpdcache_wb (HPDcache + Write-back)
          # ============================================================
          - testcase: dv-riscv-arch-test
            config: cv64a6_imafdc_sv39_hpdcache_wb
          - testcase: dv-riscv-tests
            config: cv64a6_imafdc_sv39_hpdcache_wb
            testlists: "../tests/testlist_riscv-tests-cv64a6_imafdc_sv39-p.yaml ../tests/testlist_riscv-tests-cv64a6_imafdc_sv39-v.yaml"
          - testcase: cv64a6_imafdc_tests
            config: cv64a6_imafdc_sv39_hpdcache_wb
          - testcase: benchmark
            config: cv64a6_imafdc_sv39_hpdcache_wb

          # ============================================================
          # cv64a6_imafdc_sv39_wb (Write-back variant)
          # ============================================================
          - testcase: dv-riscv-arch-test
            config: cv64a6_imafdc_sv39_wb
          - testcase: dv-riscv-tests
            config: cv64a6_imafdc_sv39_wb
            testlists: "../tests/testlist_riscv-tests-cv64a6_imafdc_sv39-p.yaml ../tests/testlist_riscv-tests-cv64a6_imafdc_sv39-v.yaml"
          - testcase: cv64a6_imafdc_tests
            config: cv64a6_imafdc_sv39_wb
          - testcase: benchmark
            config: cv64a6_imafdc_sv39_wb
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: Setup CVA6 Environment
        uses: ./.github/actions/setup-cva6-env

      - name: Install prerequisites
        run: source ci/install-prereq.sh

      - name: Run ${{ matrix.testcase }}
        run: |
          set -x
          # Create result tracking directory (before anything else)
          mkdir -p ci-results
          echo "1" > ci-results/exit_code
          source verif/sim/setup-env.sh
          # Override testlists when specified (hpdcache/wb variants share sv39 testlists)
          if [ -n "${{ matrix.testlists }}" ]; then
            export DV_TESTLISTS="${{ matrix.testlists }}"
          fi
          # Run test and capture exit code
          rc=0
          DV_SIMULATORS=veri-testharness,spike \
          DV_TARGET=${{ matrix.config }} \
            bash verif/regress/${{ matrix.testcase }}.sh || rc=$?
          # Save result (persists even if test cleans output)
          echo "$rc" > ci-results/exit_code
          # Copy iss_regr.log if available (some scripts delete output)
          find verif/sim -name "iss_regr.log" -exec cp {} ci-results/ \; 2>/dev/null || true
          exit $rc

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rv64-${{ matrix.config }}-${{ matrix.testcase }}
          path: |
            ci-results/
            verif/sim/out*/
          retention-days: 14

  # ============================================================
  # Stage 3: RV32 Test Execution (parallel matrix jobs)
  # ============================================================
  execute-rv32-tests:
    name: RV32 ${{ matrix.testcase }}
    runs-on: ubuntu-latest
    needs: setup-tools
    if: (github.event.inputs.target_arch || 'both') == 'both' || (github.event.inputs.target_arch || 'both') == 'rv32'
    strategy:
      fail-fast: false
      matrix:
        include:
          # Smoke tests - quick sanity check
          - testcase: smoke-tests-cv32a65x
            config: cv32a65x
          # Architecture compliance tests (~105 tests)
          - testcase: dv-riscv-arch-test
            config: cv32a65x
          # Standard RISC-V tests - p-mode only (~94 tests)
          # Note: cv32a65x has no MMU, so only p-mode testlist exists
          - testcase: dv-riscv-tests
            config: cv32a65x
            testlists: "../tests/testlist_riscv-tests-cv32a65x-p.yaml"
          # RISC-V compliance suite (~183 tests)
          - testcase: dv-riscv-compliance
            config: cv32a65x
          # CVA6-specific directed tests (~6 tests)
          - testcase: cv32a6_tests
            config: cv32a65x
          # CSR access verification tests
          - testcase: dv-riscv-csr-access-test
            config: cv32a65x
          # Performance benchmarks (~12 programs)
          - testcase: benchmark
            config: cv32a65x
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: Setup CVA6 Environment
        uses: ./.github/actions/setup-cva6-env

      - name: Install prerequisites
        run: source ci/install-prereq.sh

      - name: Run ${{ matrix.testcase }}
        run: |
          set -x
          # Create result tracking directory (before anything else)
          mkdir -p ci-results
          echo "1" > ci-results/exit_code
          source verif/sim/setup-env.sh
          # Override testlists when specified (e.g., cv32a65x has no v-mode tests)
          if [ -n "${{ matrix.testlists }}" ]; then
            export DV_TESTLISTS="${{ matrix.testlists }}"
          fi
          # Run test and capture exit code
          rc=0
          DV_SIMULATORS=veri-testharness,spike \
          DV_TARGET=${{ matrix.config }} \
            bash verif/regress/${{ matrix.testcase }}.sh || rc=$?
          # Save result (persists even if test cleans output)
          echo "$rc" > ci-results/exit_code
          # Copy iss_regr.log if available (some scripts delete output)
          find verif/sim -name "iss_regr.log" -exec cp {} ci-results/ \; 2>/dev/null || true
          exit $rc

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rv32-${{ matrix.config }}-${{ matrix.testcase }}
          path: |
            ci-results/
            verif/sim/out*/
          retention-days: 14

  # ============================================================
  # Stage 4: Report Summary
  # ============================================================
  report-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs:
      - execute-rv64-tests
      - execute-rv32-tests
    if: ${{ always() && !cancelled() }}
    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Generate Summary Report
        run: |
          echo "## OpenHW CVA6 Full APU Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Target Arch:** ${{ github.event.inputs.target_arch || 'both' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Arch | Test Suite | Config | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|------------|--------|--------|" >> $GITHUB_STEP_SUMMARY

          total_passed=0
          total_failed=0
          total_jobs=0
          any_failure=0

          # Process each artifact directory
          for dir in artifacts/*/; do
            if [ ! -d "$dir" ]; then
              continue
            fi
            name=$(basename "$dir")
            total_jobs=$((total_jobs + 1))

            # Parse name: {arch}-{config}-{testcase}
            arch=$(echo "$name" | cut -d'-' -f1)
            remainder=$(echo "$name" | sed "s/^${arch}-//")
            # Match longest config prefix first (order matters!)
            if [[ "$remainder" == cv64a6_imafdc_sv39_hpdcache_wb-* ]]; then
              config="cv64a6_imafdc_sv39_hpdcache_wb"
            elif [[ "$remainder" == cv64a6_imafdc_sv39_hpdcache-* ]]; then
              config="cv64a6_imafdc_sv39_hpdcache"
            elif [[ "$remainder" == cv64a6_imafdc_sv39_wb-* ]]; then
              config="cv64a6_imafdc_sv39_wb"
            elif [[ "$remainder" == cv64a6_imafdc_sv39-* ]]; then
              config="cv64a6_imafdc_sv39"
            elif [[ "$remainder" == cv32a65x-* ]]; then
              config="cv32a65x"
            else
              config="unknown"
            fi
            testcase=$(echo "$remainder" | sed "s/^${config}-//")

            # 1. Check exit code from result marker (primary source of truth)
            exit_code="missing"
            exit_code_file="$dir/ci-results/exit_code"
            if [ -f "$exit_code_file" ]; then
              exit_code=$(cat "$exit_code_file" | tr -d '[:space:]')
            fi

            # 2. Parse iss_regr.log for detailed test counts
            passed=""
            failed=""
            log_file="$dir/ci-results/iss_regr.log"
            if [ ! -f "$log_file" ]; then
              log_file=$(find "$dir" -name "iss_regr.log" 2>/dev/null | head -1)
            fi
            if [ -n "$log_file" ] && [ -f "$log_file" ]; then
              summary_line=$(grep -E "PASSED.*FAILED" "$log_file" | tail -n 1)
              if [ -n "$summary_line" ]; then
                passed=$(printf "%s" "$summary_line" | sed -n 's/.*\([0-9][0-9]*\)[[:space:]]*PASSED.*/\1/p')
                failed=$(printf "%s" "$summary_line" | sed -n 's/.*\([0-9][0-9]*\)[[:space:]]*FAILED.*/\1/p')
              fi
            fi

            # 3. Determine status (exit code takes priority over log parsing)
            if [ "$exit_code" = "0" ]; then
              # Job exited successfully
              if [ -n "$failed" ] && [ "$failed" -gt 0 ]; then
                # Exit 0 but log shows failures (shouldn't happen, but catch it)
                status="FAIL ($passed passed, $failed failed)"
                total_failed=$((total_failed + failed))
                total_passed=$((total_passed + ${passed:-0}))
                any_failure=1
              elif [ -n "$passed" ]; then
                status="PASS ($passed tests)"
                total_passed=$((total_passed + passed))
              else
                # Exit 0, no detailed log (e.g., benchmark tests)
                status="PASS"
              fi
            elif [ "$exit_code" = "missing" ]; then
              # No result marker at all
              status="UNKNOWN (no result marker)"
              any_failure=1
            else
              # Non-zero exit code = definite failure
              any_failure=1
              if [ -n "$failed" ] && [ "$failed" -gt 0 ]; then
                status="FAIL ($passed passed, $failed failed)"
                total_failed=$((total_failed + failed))
                total_passed=$((total_passed + ${passed:-0}))
              elif [ -n "$passed" ]; then
                status="FAIL (exit $exit_code, $passed tests ran)"
                total_failed=$((total_failed + 1))
                total_passed=$((total_passed + passed))
              else
                status="FAIL (exit $exit_code)"
                total_failed=$((total_failed + 1))
              fi
            fi

            echo "| ${arch} | ${testcase} | ${config} | ${status} |" >> $GITHUB_STEP_SUMMARY
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Jobs:** ${total_jobs}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Passed:** ${total_passed}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Failed:** ${total_failed}" >> $GITHUB_STEP_SUMMARY
          if [ "$any_failure" -eq 1 ]; then
            echo "- **Overall: FAILED**" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Overall: ALL PASSED**" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Generated by OpenHW CVA6 Full APU CI*" >> $GITHUB_STEP_SUMMARY

      - name: Check for failures
        run: |
          any_failed=0

          # Check each artifact's exit code
          for dir in artifacts/*/; do
            if [ ! -d "$dir" ]; then
              continue
            fi
            name=$(basename "$dir")
            exit_code_file="$dir/ci-results/exit_code"
            if [ -f "$exit_code_file" ]; then
              ec=$(cat "$exit_code_file" | tr -d '[:space:]')
              if [ "$ec" != "0" ]; then
                echo "::error::Test failed: ${name} (exit code: ${ec})"
                any_failed=1
              fi
            else
              echo "::error::Missing result marker: ${name}"
              any_failed=1
            fi
          done

          # Also check if the matrix jobs themselves reported failure
          rv64_result="${{ needs.execute-rv64-tests.result }}"
          rv32_result="${{ needs.execute-rv32-tests.result }}"
          if [ "$rv64_result" = "failure" ] && [ "$any_failed" -eq 0 ]; then
            echo "::error::RV64 matrix job reported failure but no individual failures detected in artifacts"
            any_failed=1
          fi
          if [ "$rv32_result" = "failure" ] && [ "$any_failed" -eq 0 ]; then
            echo "::error::RV32 matrix job reported failure but no individual failures detected in artifacts"
            any_failed=1
          fi

          if [ "$any_failed" -eq 1 ]; then
            echo "::error::One or more tests failed. See summary above for details."
            exit 1
          fi

          echo "All tests passed!"
